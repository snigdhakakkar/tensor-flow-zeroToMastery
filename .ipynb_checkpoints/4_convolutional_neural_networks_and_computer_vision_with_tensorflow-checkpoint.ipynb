{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c1dafc",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks and Computer Vision with Tensorflow\n",
    "\n",
    "So far we've covered the basics of TensorFlow and built a handful of models to work across different problems.\n",
    "\n",
    "Now we're going to get specific and see how a special kind of neural network, convolutional neural networks (CNNs) can be used for computer vision (detecting patterns in visual data).\n",
    "\n",
    "ðŸ”‘ Note: In deep learning, many different kinds of model architectures can be used for different problems. For example, you could use a convolutional neural network for making predictions on image data and/or text data. However, in practice some architectures typically work better than others.\n",
    "\n",
    "For example, you might want to:\n",
    "\n",
    "Classify whether a picture of food contains pizza ðŸ• or steak ðŸ¥© (we're going to do this)\n",
    "Detect whether or not an object appears in an image (e.g. did a specific car pass through a security camera?)\n",
    "In this notebook, we're going to follow the TensorFlow modelling workflow we've been following so far whilst learning about how to build and use CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cc2c90",
   "metadata": {},
   "source": [
    "## What we're going to cover\n",
    "\n",
    "Specifically, we're going to go through the follow with TensorFlow:\n",
    "\n",
    "* Getting a dataset to work with\n",
    "* Architecture of a convolutional neural network\n",
    "* A quick end-to-end example (what we're working towards)\n",
    "* Steps in modelling for binary image classification with CNNs\n",
    "    * Becoming one with the data\n",
    "    * Preparing data for modelling\n",
    "    * Creating a CNN model (starting with a baseline)\n",
    "    * Fitting a model (getting it to find patterns in our data)\n",
    "    * Evaluating a model\n",
    "    * Improving a model\n",
    "    * Making a prediction with a trained model\n",
    "* Steps in modelling for multi-class image classification with CNNs\n",
    "* Same as above (but this time with a different dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f575cf8",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "\n",
    "Because convolutional neural networks work so well with images, to learn more about them, we're going to start with a dataset of images.\n",
    "\n",
    "The images we're going to work with are from the [Food-101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/), a collection of 101 different categories of 101,000 (1000 images per category) real-world images of food dishes.\n",
    "\n",
    "To begin, we're only going to use two of the categories, pizza ðŸ• and steak ðŸ¥© and build a binary classifier.\n",
    "\n",
    "ðŸ”‘ Note: To prepare the data we're using, [preprocessing steps](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb) such as, moving the images into different subset folders, have been done. To see these preprocessing steps check out the preprocessing notebook.\n",
    "\n",
    "We'll download the ```pizza_steak``` subset .zip file and unzip it.\n",
    "\n",
    "Note for preprocessing steps:\n",
    "\n",
    "To replicate this notebook you'll need the data downloaded from either of the following:\n",
    "\n",
    "https://www.kaggle.com/kmader/food41\n",
    "https://www.kaggle.com/dansbecker/food-101 (this also works)\n",
    "However, the code below works on the first link's file structure.\n",
    "\n",
    "Once you've got the raw zip file, unzip it and put in the current working directory.\n",
    "\n",
    "The following code should run to create the following data splits (based on what you downloaded from above):\n",
    "\n",
    "Binary dataset (split steak/pizza into train & test folders)\n",
    "Binary dataset of 10% of data (split steak/pizza into & test folders)\n",
    "10 class dataset (split 10 classes into train & test folders)\n",
    "10 class dataset of 10% of data (select random 10% of training data, keep test data the same)\n",
    "Create all class dataset (split all classes into train & test folders)\n",
    "Create all class dataset with 10% of data (select random 10% of training data, keep test data the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a857f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-11 02:49:17--  https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.41.80, 172.217.165.16, 142.251.32.80, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.41.80|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 109540975 (104M) [application/zip]\n",
      "Saving to: â€˜pizza_steak.zipâ€™\n",
      "\n",
      "pizza_steak.zip     100%[===================>] 104.47M  19.5MB/s    in 5.3s    \n",
      "\n",
      "2022-12-11 02:49:23 (19.6 MB/s) - â€˜pizza_steak.zipâ€™ saved [109540975/109540975]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Download zip file of pizza_steak images\n",
    "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip \n",
    "\n",
    "# Unzip the downloaded file\n",
    "zip_ref = zipfile.ZipFile(\"pizza_steak.zip\", \"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf10f3dc",
   "metadata": {},
   "source": [
    "## Inspect the data (become one with it)\n",
    "\n",
    "A very crucial step at the beginning of any machine learning project is becoming one with the data. This usually means plenty of visualizing and folder scanning to understand the data you're working with.\n",
    "\n",
    "Wtih this being said, let's inspect the data we just downloaded.\n",
    "\n",
    "The file structure has been formatted to be in a typical format you might use for working with images.\n",
    "\n",
    "More specifically:\n",
    "\n",
    "* A **train directory** which contains all of the images in the training dataset with subdirectories each named after a certain class containing images of that class.\n",
    "* A **test directory** with the same structure as the train directory.\n",
    "\n",
    "![pizza_steak_Data.png](Images/pizza_steak_Data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23baf695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mtest\u001b[m\u001b[m  \u001b[34mtrain\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls pizza_steak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431df33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
